"""
ServiÃ§o de IA para processamento de linguagem natural
Integrado com mÃºltiplos LLMs via LLMService
"""
import json
import re
from typing import Dict, Any, List
from .llm_service import llm_service

def processar_pergunta(pergunta: str, provider: str = None) -> Dict[str, Any]:
    """
    Processa pergunta em linguagem natural usando IA
    
    Args:
        pergunta: Pergunta do usuÃ¡rio
        provider: Provedor especÃ­fico de LLM (opcional)
    
    Returns:
        Dict com anÃ¡lise da pergunta
    """
    
    # Prompt melhorado para anÃ¡lise de consultas eleitorais
    prompt = f"""
VocÃª Ã© um assistente especializado em anÃ¡lise de dados eleitorais do Distrito Federal 2022.

CONTEXTO DOS DADOS:
- 590 candidatos a deputado distrital
- 19 zonas eleitorais
- 6.748 seÃ§Ãµes eleitorais  
- 107 locais de votaÃ§Ã£o
- 1.535.545 votos totais

MAPEAMENTO DE REGIÃ•ES â†’ ZONAS:
- BrasÃ­lia/Plano Piloto â†’ Zona 1
- Gama â†’ Zona 2  
- Taguatinga â†’ Zona 3
- BrazlÃ¢ndia â†’ Zona 4
- Sobradinho â†’ Zona 5
- Planaltina â†’ Zona 6
- NÃºcleo Bandeirante â†’ Zona 8
- CeilÃ¢ndia â†’ Zona 9
- GuarÃ¡ â†’ Zona 10
- Cruzeiro â†’ Zona 11
- Sobradinho II â†’ Zona 13
- Samambaia â†’ Zona 14
- SÃ£o SebastiÃ£o â†’ Zona 15
- Recanto das Emas â†’ Zona 16
- Lago Sul â†’ Zona 17
- Riacho Fundo â†’ Zona 18
- Ãguas Claras â†’ Zona 19
- Vicente Pires â†’ Zona 20
- ParanoÃ¡ â†’ Zona 21

TIPOS DE CONSULTA DISPONÃVEIS:
1. mais_votados - Top candidatos geral
2. candidatos_zona - Candidatos por zona/regiÃ£o
3. buscar_candidato - Buscar por nome
4. votos_candidato_regiao - Votos de candidato por regiÃ£o(Ãµes)
5. votos_candidato_secao - Votos de candidato por seÃ§Ã£o
6. comparar_regioes - Comparar votaÃ§Ã£o entre regiÃµes
7. ranking_local - Ranking por local de votaÃ§Ã£o
8. estatisticas - EstatÃ­sticas gerais
9. zonas - Listar zonas
10. locais - Listar locais

EXEMPLOS DE ANÃLISE:
- "Top 5 candidatos" â†’ tipo: mais_votados, limite: 5
- "Candidatos em CeilÃ¢ndia" â†’ tipo: candidatos_zona, zona: 9, regiao: "ceilÃ¢ndia"
- "Buscar JoÃ£o Silva" â†’ tipo: buscar_candidato, nome_candidato: "JoÃ£o Silva"
- "Quantos votos FÃ¡bio Felix teve em Taguatinga?" â†’ tipo: votos_candidato_regiao, candidato_especifico: "FÃ¡bio Felix", regiao: "taguatinga"
- "Votos de Marcos na seÃ§Ã£o 123" â†’ tipo: votos_candidato_secao, candidato_especifico: "Marcos", secao: 123
- "Comparar CeilÃ¢ndia e Samambaia" â†’ tipo: comparar_regioes, regioes_comparar: ["ceilÃ¢ndia", "samambaia"]

PERGUNTA DO USUÃRIO: "{pergunta}"

Analise a pergunta e retorne APENAS um JSON vÃ¡lido com:
{{
    "tipo_consulta": "tipo_identificado",
    "parametros": {{
        "limite": numero_se_aplicavel,
        "zona": numero_zona_se_aplicavel,
        "regiao": "nome_regiao_se_aplicavel",
        "nome_candidato": "nome_se_busca",
        "candidato_especifico": "nome_candidato_se_consulta_especifica",
        "secao": numero_secao_se_aplicavel,
        "regioes_comparar": ["regiao1", "regiao2"],
        "local_votacao": "nome_local_se_aplicavel"
    }},
    "explicacao": "breve_explicacao_da_analise"
}}

Se nÃ£o conseguir identificar, retorne:
{{
    "tipo_consulta": "erro",
    "parametros": {{}},
    "explicacao": "NÃ£o foi possÃ­vel entender a pergunta"
}}
"""

    messages = [
        {"role": "system", "content": "VocÃª Ã© um assistente especializado em anÃ¡lise de consultas eleitorais. Responda sempre em JSON vÃ¡lido."},
        {"role": "user", "content": prompt}
    ]
    
    try:
        # Usar LLM service com fallback automÃ¡tico
        result = llm_service.chat_completion(
            messages=messages,
            provider=provider,
            temperature=0.1,
            max_tokens=500
        )
        
        if not result['success']:
            return {
                'tipo_consulta': 'erro',
                'parametros': {},
                'explicacao': f'Erro na IA: {result.get("error", "Erro desconhecido")}',
                'provider_info': result
            }
        
        # Tentar parsear JSON da resposta
        try:
            analise = json.loads(result['content'])
            
            # Adicionar informaÃ§Ãµes do provedor usado
            analise['provider_info'] = {
                'provider': result['provider'],
                'model': result['model'],
                'cost': result.get('cost', {}),
                'usage': result.get('usage', {})
            }
            
            return analise
            
        except json.JSONDecodeError:
            # Fallback: tentar extrair JSON da resposta
            json_match = re.search(r'\{.*\}', result['content'], re.DOTALL)
            if json_match:
                try:
                    analise = json.loads(json_match.group())
                    analise['provider_info'] = {
                        'provider': result['provider'],
                        'model': result['model']
                    }
                    return analise
                except:
                    pass
            
            return {
                'tipo_consulta': 'erro',
                'parametros': {},
                'explicacao': 'Resposta da IA nÃ£o estÃ¡ em formato JSON vÃ¡lido',
                'raw_response': result['content'],
                'provider_info': result
            }
    
    except Exception as e:
        return {
            'tipo_consulta': 'erro',
            'parametros': {},
            'explicacao': f'Erro ao processar pergunta: {str(e)}'
        }

def gerar_resposta_natural(pergunta: str, dados: Dict[str, Any], provider: str = None) -> str:
    """
    Gera resposta em linguagem natural baseada nos dados
    
    Args:
        pergunta: Pergunta original do usuÃ¡rio
        dados: Dados retornados pela consulta
        provider: Provedor especÃ­fico de LLM (opcional)
    
    Returns:
        Resposta em linguagem natural
    """
    
    prompt = f"""
VocÃª Ã© um assistente especializado em eleiÃ§Ãµes do DF 2022.

PERGUNTA DO USUÃRIO: "{pergunta}"

DADOS ENCONTRADOS: {json.dumps(dados, ensure_ascii=False, indent=2)}

Gere uma resposta natural, clara e informativa baseada nos dados. 

DIRETRIZES:
- Use linguagem brasileira informal mas profissional
- Destaque os nÃºmeros mais importantes
- Se houver muitos resultados, foque nos principais
- Use emojis moderadamente (ðŸ“Š, ðŸ—³ï¸, ðŸ†)
- Seja conciso mas completo
- Se nÃ£o houver dados, explique de forma amigÃ¡vel

FORMATO DA RESPOSTA:
- Resposta direta Ã  pergunta
- Principais resultados com nÃºmeros
- Contexto adicional se relevante
"""

    messages = [
        {"role": "system", "content": "VocÃª Ã© um assistente especializado em dados eleitorais. Responda de forma natural e informativa."},
        {"role": "user", "content": prompt}
    ]
    
    try:
        result = llm_service.chat_completion(
            messages=messages,
            provider=provider,
            temperature=0.3,
            max_tokens=800
        )
        
        if result['success']:
            return result['content']
        else:
            return f"Encontrei os dados solicitados, mas tive dificuldade para formatÃ¡-los. Consulte os dados retornados para mais detalhes."
    
    except Exception as e:
        return f"Dados encontrados com sucesso. Erro na formataÃ§Ã£o da resposta: {str(e)}"

def obter_status_ia() -> Dict[str, Any]:
    """Retorna status completo do serviÃ§o de IA"""
    return llm_service.get_status()

def testar_provedores() -> Dict[str, Any]:
    """Testa todos os provedores de LLM"""
    return llm_service.test_providers()

